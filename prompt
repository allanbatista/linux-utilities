#!/usr/bin/env python3
import argparse
import os
import pathlib
import json
import requests
import pyperclip
import datetime
import sys

def save_to_history(prompt: str, response: str):
    """
    Salva o prompt e a resposta em um arquivo de histórico em ~/.prompt/

    Args:
        prompt: O prompt completo enviado para a API.
        response: A resposta de texto recebida da API.
    """
    try:
        history_dir = pathlib.Path.home() / '.prompt'
        history_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
        filename = f"{timestamp}.txt"
        filepath = history_dir / filename

        content = f"# Prompt\n\n{prompt}\n\n# Response\n\n{response}\n"

        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print(f"✅ Histórico salvo em: {filepath}")

    except Exception as e:
        print(f"Erro ao salvar o histórico: {e}")


def send_to_gemini(prompt: str, context: str, lang: str, specialist: str | None, model_name: str) -> dict | None:
    """
    Envia o prompt e o contexto para a API REST do Gemini.

    Args:
        prompt: O prompt do usuário.
        context: O conteúdo dos arquivos concatenados.
        lang: A linguagem de output desejada.
        specialist: A persona especialista a ser usada (ou None).
        model_name: O nome do modelo do Gemini a ser usado.

    Returns:
        Um dicionário com a resposta ou None em caso de erro.
    """
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        print("Erro: A variável de ambiente GEMINI_API_KEY não está definida.")
        return None

    specialist_prompts = {
        'dev': 'Aja como um programador sênior especialista em desenvolvimento de software, com mais de 20 anos de experiência. Suas respostas devem ser claras, eficientes, bem-estruturadas e seguir as melhores práticas do mercado. Pense passo a passo.',
        'rm': 'Aja como um analista de Retail Media sênior, especialista em estratégias de publicidade digital para e-commerce e marketplaces. Seu conhecimento abrange plataformas como Amazon Ads, Mercado Ads e Criteo. Suas respostas devem ser analíticas, estratégicas e baseadas em dados.'
    }
    
    prompt_parts = []
    
    if specialist and specialist in specialist_prompts:
        prompt_parts.append(specialist_prompts[specialist])
    
    prompt_parts.append(f"{prompt}\n\n--- CONTEXTO DOS ARQUIVOS ---\n\n{context}")
    prompt_parts.append(f"--- INSTRUÇÃO DE SAÍDA ---\nResponda estritamente na linguagem: {lang}.")
    
    full_prompt = "\n\n".join(prompt_parts)
    api_version = 'v1beta'
    url = f"https://generativelanguage.googleapis.com/{api_version}/models/{model_name}:generateContent?key={api_key}"
    payload = {"contents": [{"parts": [{"text": full_prompt}]}]}
    headers = {"Content-Type": "application/json"}

    try:
        print(f"Enviando requisição para o modelo {model_name} (API {api_version})...")
        response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=300)
        response.raise_for_status()
        
        response_data = response.json()
        text_response = response_data['candidates'][0]['content']['parts'][0]['text']
        usage_metadata = response_data.get('usageMetadata', {})
        prompt_tokens = usage_metadata.get('promptTokenCount', 'N/A')
        response_tokens = usage_metadata.get('candidatesTokenCount', 'N/A')
        
        return {
            "text": text_response,
            "prompt_tokens": prompt_tokens,
            "response_tokens": response_tokens,
            "full_prompt": full_prompt
        }

    except requests.exceptions.RequestException as e:
        print(f"Ocorreu um erro de rede ou HTTP ao chamar a API do Gemini: {e}")
        if e.response is not None:
            print(f"Detalhes do erro: {e.response.text}")
        return None
    except (KeyError, IndexError) as e:
        print(f"Erro ao extrair o conteúdo da resposta da API: {e}")
        print("Estrutura da resposta recebida:", response.json())
        return None
    except Exception as e:
        print(f"Um erro inesperado ocorreu: {e}")
        return None

def process_file(file_path: pathlib.Path, path_format: str, max_tokens_doc: int) -> tuple[str, int, int]:
    """
    Lê o conteúdo de um arquivo, formata o cabeçalho e trunca se necessário com base em tokens.

    Args:
        file_path: O caminho do arquivo a ser processado.
        path_format: Como o caminho deve ser formatado ('full', 'relative', 'name_only').
        max_tokens_doc: O número máximo de tokens estimados para este arquivo.

    Returns:
        Uma tupla contendo o conteúdo formatado, a contagem de palavras e os tokens estimados.
    """
    try:
        display_path = ""
        if path_format == 'name_only':
            display_path = file_path.name
        elif path_format == 'relative':
            display_path = os.path.relpath(file_path.resolve(), pathlib.Path.cwd())
        else: # 'full'
            display_path = str(file_path.resolve())

        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
        
        original_tokens = len(content) // 4
        warning_message = ""

        if original_tokens > max_tokens_doc:
            max_chars = max_tokens_doc * 4
            content = content[:max_chars]
            warning_message = (
                f"// warning_content_truncated=\"true\" "
                f"original_token_count=\"{original_tokens}\" "
                f"new_token_count=\"{max_tokens_doc}\"\n"
            )
            print(f"  -> Aviso: O arquivo '{display_path}' foi truncado para ~{max_tokens_doc} tokens.")

        word_count = len(content.split())
        estimated_tokens = len(content) // 4
        formatted_content = f"// filename=\"{display_path}\"\n{warning_message}{content}\n"
        
        return formatted_content, word_count, estimated_tokens
    except Exception as e:
        error_message = f"// error_processing_file=\"{file_path.resolve()}\"\n// Error: {e}\n"
        return error_message, 0, 0

def main():
    """Função principal que orquestra a execução do script."""
    ALLOWED_EXTENSIONS = {
        '.txt', '.py', '.rb', '.rs', '.html', '.css', '.js', '.ts', '.cs',
        '.sh', '.md', '.c', '.cpp', '.hpp', '.h', '.json', '.yml', '.yaml',
        '.jsonl', '.xml', '.scss'
    }

    parser = argparse.ArgumentParser(
        description="Concatena o conteúdo de arquivos com extensões permitidas e opcionalmente envia para a API do Gemini.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument(
        "paths",
        metavar="PATH",
        type=pathlib.Path,
        nargs='*',
        help="Uma lista de arquivos e/ou diretórios para processar."
    )
    parser.add_argument(
        "-p", "--prompt",
        type=str,
        help="Um prompt opcional para enviar à API do Gemini junto com o conteúdo dos arquivos."
    )
    parser.add_argument(
        '--lang',
        type=str,
        default='pt-br',
        help='Linguagem de output desejada. Padrão: pt-br'
    )
    parser.add_argument(
        '-n', '--max-tokens',
        type=int,
        default=900_000,
        help='Tamanho máximo em tokens estimados para o contexto total. Padrão: 900000'
    )
    parser.add_argument(
        '-nn', '--max-tokens-doc',
        type=int,
        default=250_000,
        help='Tamanho máximo em tokens estimados para cada arquivo individual. Padrão: 250000'
    )
    parser.add_argument(
        '-s', '--specialist',
        type=str,
        choices=['dev', 'rm'],
        help="Define uma persona especialista:\n"
             "'dev' para Programador Sênior\n"
             "'rm'  para Analista de Retail Media Sênior."
    )
    parser.add_argument(
        '--model',
        type=str,
        default='gemini-1.5-flash-latest',
        choices=['gemini-1.5-pro-latest', 'gemini-1.5-flash-latest'],
        help='O modelo do Gemini a ser usado. Padrão: gemini-1.5-flash-latest'
    )

    path_options = parser.add_mutually_exclusive_group()
    path_options.add_argument(
        "--relative-paths",
        action="store_true",
        help="Exibe caminhos relativos em vez de caminhos absolutos."
    )
    path_options.add_argument(
        "--filename-only",
        action="store_true",
        help="Exibe apenas o nome do arquivo em vez do caminho completo."
    )
    
    # Se nenhum argumento for passado, exibe a ajuda
    if len(sys.argv) == 1:
        parser.print_help(sys.stderr)
        sys.exit(1)

    args = parser.parse_args()

    path_format_option = 'full'
    if args.relative_paths:
        path_format_option = 'relative'
    elif args.filename_only:
        path_format_option = 'name_only'

    all_files_content = []
    total_word_count = 0
    total_estimated_tokens = 0
    files_processed_count = 0
    files_error_count = 0
    files_skipped_count = 0

    for path_arg in args.paths:
        if not path_arg.exists():
            print(f"Aviso: O caminho '{path_arg}' não existe. Pulando.")
            continue

        if path_arg.is_file():
            if path_arg.suffix in ALLOWED_EXTENSIONS:
                content, word_count, estimated_tokens = process_file(path_arg, path_format_option, args.max_tokens_doc)
                print(f"Processando arquivo: {path_arg.resolve()} ({word_count} palavras, ~{estimated_tokens} tokens)")
                if content.startswith("// error_processing_file"):
                    files_error_count += 1
                else:
                    files_processed_count += 1
                    total_word_count += word_count
                    total_estimated_tokens += estimated_tokens
                all_files_content.append(content)
            else:
                print(f"Aviso: Arquivo com extensão não permitida '{path_arg.suffix}' foi ignorado: {path_arg}")
                files_skipped_count += 1
        
        elif path_arg.is_dir():
            print(f"Processando diretório: {path_arg.resolve()}")
            for child_path in path_arg.rglob('*'):
                if child_path.is_file():
                    if child_path.suffix in ALLOWED_EXTENSIONS:
                        content, word_count, estimated_tokens = process_file(child_path, path_format_option, args.max_tokens_doc)
                        print(f"  -> Processando: {child_path.relative_to(path_arg)} ({word_count} palavras, ~{estimated_tokens} tokens)")
                        if content.startswith("// error_processing_file"):
                            files_error_count += 1
                        else:
                            files_processed_count += 1
                            total_word_count += word_count
                            total_estimated_tokens += estimated_tokens
                        all_files_content.append(content)
                    else:
                        files_skipped_count += 1
        else:
            print(f"Aviso: O caminho '{path_arg}' não é um arquivo nem um diretório. Pulando.")

    if not all_files_content:
        # Se não houver arquivos, mas o prompt existir, continue para a API
        if not args.prompt:
            print("\nNenhum arquivo válido foi encontrado ou processado.")
            if files_skipped_count > 0:
                print(f"{files_skipped_count} arquivo(s) foram ignorados devido à extensão não permitida.")
            return

    final_text = "".join(all_files_content)

    original_total_tokens = len(final_text) // 4
    if original_total_tokens > args.max_tokens:
        print(f"\nAviso: O contexto final com ~{original_total_tokens} tokens excedeu o limite de {args.max_tokens}. Truncando...")
        max_chars = args.max_tokens * 4
        final_text = final_text[:max_chars]
        print(f"Novo total de tokens estimados no contexto: ~{len(final_text) // 4}")

    if args.prompt:
        gemini_result = send_to_gemini(args.prompt, final_text, args.lang, args.specialist, args.model)
        if gemini_result:
            response_text = gemini_result['text']
            
            print("\n--- INFORMAÇÕES DA REQUISIÇÃO ---")
            print(f"Modelo Utilizado: {args.model}")
            print(f"Arquivos Processados: {files_processed_count} ({total_word_count} palavras, ~{total_estimated_tokens} tokens) | Erros: {files_error_count} | Ignorados: {files_skipped_count}")
            print(f"Tokens Enviados (Contagem Real da API): {gemini_result['prompt_tokens']}")
            print(f"Tokens Recebidos (Contagem Real da API): {gemini_result['response_tokens']}")
            print("---------------------------------")
            
            print("\n--- RESPOSTA DO GEMINI ---\n")
            print(response_text)
            print("\n--------------------------\n")
            
            try:
                pyperclip.copy(response_text)
                print("✅ Resposta do Gemini copiada para a área de transferência!")
            except pyperclip.PyperclipException as e:
                print(f"Erro: Não foi possível copiar para a área de transferência. {e}")

            save_to_history(gemini_result['full_prompt'], response_text)

    # Se não houver prompt, mas houver conteúdo de arquivo, copie para o clipboard
    elif final_text:
        try:
            pyperclip.copy(final_text)
            print(f"\nProcessado(s) {files_processed_count} arquivo(s) com sucesso ({total_word_count} palavras, ~{total_estimated_tokens} tokens no total).")
            if files_skipped_count > 0:
                 print(f"{files_skipped_count} arquivo(s) foram ignorados devido à extensão não permitida.")
            if files_error_count > 0:
                print(f"Encontrados erros em {files_error_count} arquivo(s).")
            print("✅ O conteúdo combinado foi copiado para a sua área de transferência!")
        except pyperclip.PyperclipException as e:
            print(f"\nErro: Não foi possível copiar para a área de transferência. {e}")
            print("\nAqui está a saída combinada:\n")
            print("--------------------------------------------------")
            print(final_text)
            print("--------------------------------------------------")

if __name__ == "__main__":
    main()
